# ä»»åŠ¡å¤„ç†è¯¦ç»†æµç¨‹

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†æ–‡æ¡£è½¬æ¢æœåŠ¡çš„ä»»åŠ¡å¤„ç†æµç¨‹ï¼ŒåŒ…æ‹¬æ¯ä¸ªé˜¶æ®µçš„å…·ä½“æ“ä½œã€çŠ¶æ€å˜åŒ–å’Œé”™è¯¯å¤„ç†æœºåˆ¶ã€‚

## ğŸ”„ ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸæ¦‚è§ˆ

```mermaid
graph TD
    A[ä»»åŠ¡åˆ›å»º] --> B[å‚æ•°éªŒè¯]
    B --> C[ä»»åŠ¡å…¥é˜Ÿ]
    C --> D[ç­‰å¾…å¤„ç†]
    D --> E[å·¥ä½œç©ºé—´åˆ›å»º]
    E --> F[S3æ–‡ä»¶ä¸‹è½½]
    F --> G[æ–‡æ¡£è½¬æ¢]
    G --> H[ç»“æœä¸Šä¼ S3]
    H --> I[ä»»åŠ¡å®Œæˆ]
    
    B --> J[å‚æ•°é”™è¯¯]
    F --> K[ä¸‹è½½å¤±è´¥]
    G --> L[è½¬æ¢å¤±è´¥]
    H --> M[ä¸Šä¼ å¤±è´¥]
    
    J --> N[ä»»åŠ¡å¤±è´¥]
    K --> O[é‡è¯•æœºåˆ¶]
    L --> O
    M --> O
    O --> P[é‡è¯•æ¬¡æ•°æ£€æŸ¥]
    P --> Q[ç»§ç»­é‡è¯•]
    P --> N
    Q --> F
```

## ğŸ“‹ ä»»åŠ¡çŠ¶æ€è¯¦è§£

### çŠ¶æ€æšä¸¾
| çŠ¶æ€ | æè¿° | å¯è½¬æ¢çŠ¶æ€ |
|------|------|------------|
| `pending` | ç­‰å¾…å¤„ç† | `processing`, `failed` |
| `processing` | æ­£åœ¨å¤„ç† | `completed`, `failed` |
| `completed` | å¤„ç†å®Œæˆ | - |
| `failed` | å¤„ç†å¤±è´¥ | `pending` (é‡è¯•) |

### çŠ¶æ€è½¬æ¢æ—¶æœº
1. **pending â†’ processing**: å·¥ä½œçº¿ç¨‹å¼€å§‹å¤„ç†ä»»åŠ¡
2. **processing â†’ completed**: æ‰€æœ‰æ­¥éª¤æˆåŠŸå®Œæˆ
3. **processing â†’ failed**: ä»»ä½•æ­¥éª¤å‘ç”Ÿä¸å¯æ¢å¤é”™è¯¯
4. **failed â†’ pending**: æ‰‹åŠ¨é‡è¯•æˆ–è‡ªåŠ¨é‡è¯•

## ğŸš€ è¯¦ç»†å¤„ç†æµç¨‹

### 1. ä»»åŠ¡åˆ›å»ºé˜¶æ®µ

#### 1.1 APIè¯·æ±‚æ¥æ”¶
```http
POST /api/tasks/create
Content-Type: multipart/form-data

task_type=pdf_to_markdown
bucket_name=documents
file_path=reports/annual_report.pdf
platform=your-platform
priority=high
```

#### 1.2 å‚æ•°éªŒè¯
- **task_type**: éªŒè¯æ˜¯å¦ä¸ºæ”¯æŒçš„ç±»å‹
- **bucket_name**: éªŒè¯S3å­˜å‚¨æ¡¶åç§°æ ¼å¼
- **file_path**: éªŒè¯æ–‡ä»¶è·¯å¾„æ ¼å¼
- **priority**: éªŒè¯ä¼˜å…ˆçº§å€¼

#### 1.3 ä»»åŠ¡å¯¹è±¡åˆ›å»º
```python
task = DocumentTask(
    task_type="pdf_to_markdown",
    bucket_name="documents",
    file_path="reports/annual_report.pdf",
    platform="your-platform",
    priority="high",
    status="pending",
    created_at=datetime.utcnow()
)
```

#### 1.4 æ•°æ®åº“å­˜å‚¨
- ç”Ÿæˆå”¯ä¸€ä»»åŠ¡ID
- å­˜å‚¨åˆ°SQLite/PostgreSQLæ•°æ®åº“
- è¿”å›ä»»åŠ¡åˆ›å»ºå“åº”

### 2. ä»»åŠ¡è°ƒåº¦é˜¶æ®µ

#### 2.1 ä¼˜å…ˆçº§é˜Ÿåˆ—
```python
# é˜Ÿåˆ—ä¼˜å…ˆçº§é¡ºåº
high_priority_queue    # ç«‹å³å¤„ç†
normal_priority_queue  # æ­£å¸¸å¤„ç†
low_priority_queue     # æœ€åå¤„ç†
```

#### 2.2 å·¥ä½œçº¿ç¨‹åˆ†é…
- æ£€æŸ¥å¯ç”¨å·¥ä½œçº¿ç¨‹
- æŒ‰ä¼˜å…ˆçº§ä»é˜Ÿåˆ—å–ä»»åŠ¡
- åˆ†é…ç»™ç©ºé—²å·¥ä½œçº¿ç¨‹

### 3. ä»»åŠ¡æ‰§è¡Œé˜¶æ®µ

#### 3.1 å·¥ä½œç©ºé—´åˆ›å»º
```bash
# åˆ›å»ºä»»åŠ¡ä¸“ç”¨å·¥ä½œç©ºé—´
/app/task_workspace/task_{task_id}/
â”œâ”€â”€ input/          # è¾“å…¥æ–‡ä»¶ç›®å½•
â”œâ”€â”€ output/         # è¾“å‡ºæ–‡ä»¶ç›®å½•
â””â”€â”€ temp/           # ä¸´æ—¶æ–‡ä»¶ç›®å½•
```

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-08-09 19:38:35 - utils.workspace_manager - INFO - Created task workspace: /app/task_workspace/task_123
```

#### 3.2 S3æ–‡ä»¶ä¸‹è½½
```python
# S3ä¸‹è½½æµç¨‹
s3_client = create_s3_client()
download_path = f"/app/task_workspace/task_{task_id}/input/{filename}"
s3_client.download_file(bucket_name, file_path, download_path)
```

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-08-09 19:38:35 - services.s3_download_service - INFO - Starting download from s3://documents/reports/annual_report.pdf
2025-08-09 19:38:35 - services.s3_download_service - INFO - File info - Size: 1048576 bytes, Type: application/pdf
2025-08-09 19:38:35 - services.s3_download_service - INFO - Successfully downloaded 1048576 bytes in 0.50s
```

#### 3.3 æ–‡æ¡£è½¬æ¢å¤„ç†

##### PDFè½¬Markdownæµç¨‹
```python
# 1. åŠ è½½PDFæ–‡ä»¶
pdf_document = load_pdf(input_path)

# 2. MinerUåˆ†æ
analysis_result = mineru_pipeline.analyze(pdf_document)

# 3. å†…å®¹æå–
markdown_content = extract_markdown(analysis_result)
json_structure = extract_structure(analysis_result)
images = extract_images(analysis_result)

# 4. ä¿å­˜ç»“æœ
save_markdown(output_path, markdown_content)
save_json(output_path, json_structure)
save_images(output_path, images)
```

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-08-09 19:38:36 - services.document_service - INFO - Converting PDF to Markdown: input.pdf -> output.md
2025-08-09 19:38:36 - services.document_service - INFO - Using MinerU 2.0 Python API to convert PDF
2025-08-09 19:38:36 - services.document_service - INFO - PDF file loaded: annual_report, size: 1048576 bytes
2025-08-09 19:38:36 - services.document_service - INFO - Starting MinerU pipeline analysis...
2025-08-09 19:40:26 - services.document_service - INFO - MinerU analysis completed, processing results...
2025-08-09 19:40:59 - services.document_service - INFO - MinerU conversion completed successfully
```

##### Officeè½¬PDFæµç¨‹
```python
# 1. LibreOfficeè½¬æ¢
libreoffice_cmd = [
    "/usr/bin/libreoffice",
    "--headless",
    "--convert-to", "pdf",
    "--outdir", output_dir,
    input_path
]
subprocess.run(libreoffice_cmd, timeout=300)
```

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-08-09 19:42:00 - services.document_service - INFO - Converting Office document to PDF: input.docx -> output.pdf
2025-08-09 19:42:07 - services.document_service - INFO - Office to PDF conversion completed successfully
```

#### 3.4 S3ç»“æœä¸Šä¼ 

##### è·¯å¾„è§£æé€»è¾‘
```python
# è¾“å…¥: s3://documents/reports/annual_report.pdf
# è§£æç»“æœ:
original_bucket = "documents"
file_name = "annual_report"
conversion_type = "markdown"  # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®š

# è¾“å‡ºè·¯å¾„: s3://ai-file/documents/annual_report/markdown/
output_prefix = f"ai-file/{original_bucket}/{file_name}/{conversion_type}/"
```

##### æ–‡ä»¶ä¸Šä¼ æµç¨‹
```python
# ä¸Šä¼ æ‰€æœ‰è¾“å‡ºæ–‡ä»¶
for file in output_files:
    s3_key = f"{output_prefix}{file.name}"
    s3_client.upload_file(file.path, "ai-file", s3_key)
    s3_urls.append(f"s3://ai-file/{s3_key}")
```

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-08-09 19:41:00 - services.s3_upload_service - INFO - Starting upload to s3://ai-file/documents/annual_report/markdown/annual_report.md
2025-08-09 19:41:00 - services.s3_upload_service - INFO - Successfully uploaded 19988 bytes in 0.25s
2025-08-09 19:41:02 - services.s3_upload_service - INFO - Complete conversion result uploaded: 6 files, 916094 bytes
```

### 4. ä»»åŠ¡å®Œæˆé˜¶æ®µ

#### 4.1 çŠ¶æ€æ›´æ–°
```python
task.status = "completed"
task.completed_at = datetime.utcnow()
task.task_processing_time = (completed_at - started_at).total_seconds()
task.output_url = main_output_s3_url
task.s3_urls = all_s3_urls
```

#### 4.2 å·¥ä½œç©ºé—´æ¸…ç†
```python
# å¯é€‰ï¼šæ¸…ç†ä¸´æ—¶æ–‡ä»¶
if cleanup_enabled:
    shutil.rmtree(task_workspace_path)
```

## âš ï¸ é”™è¯¯å¤„ç†æœºåˆ¶

### é”™è¯¯ç±»å‹åˆ†ç±»

#### 1. å¯é‡è¯•é”™è¯¯
- **ç½‘ç»œé”™è¯¯**: S3è¿æ¥è¶…æ—¶ã€ç½‘ç»œä¸­æ–­
- **ä¸´æ—¶èµ„æºä¸è¶³**: GPUå†…å­˜ä¸è¶³ã€ç£ç›˜ç©ºé—´ä¸è¶³
- **æœåŠ¡æš‚æ—¶ä¸å¯ç”¨**: S3æœåŠ¡ä¸´æ—¶æ•…éšœ

#### 2. ä¸å¯é‡è¯•é”™è¯¯
- **æ–‡ä»¶ä¸å­˜åœ¨**: S3ä¸­æ‰¾ä¸åˆ°æŒ‡å®šæ–‡ä»¶
- **æ ¼å¼ä¸æ”¯æŒ**: æ–‡ä»¶æ ¼å¼ä¸è¢«æ”¯æŒ
- **æƒé™é”™è¯¯**: S3è®¿é—®æƒé™ä¸è¶³
- **å‚æ•°é”™è¯¯**: ä»»åŠ¡å‚æ•°æ ¼å¼é”™è¯¯

### é‡è¯•ç­–ç•¥

#### è‡ªåŠ¨é‡è¯•
```python
max_retry_count = 3
retry_delay = [30, 60, 120]  # ç§’

for attempt in range(max_retry_count):
    try:
        process_task()
        break
    except RetryableError as e:
        if attempt < max_retry_count - 1:
            time.sleep(retry_delay[attempt])
            continue
        else:
            mark_task_failed()
```

#### æ‰‹åŠ¨é‡è¯•
```bash
# é‡è¯•å•ä¸ªä»»åŠ¡
curl -X POST "http://localhost:8000/api/tasks/123/retry"

# æ‰¹é‡é‡è¯•å¤±è´¥ä»»åŠ¡
curl -X POST "http://localhost:8000/api/tasks/retry-failed"
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡
- **ä»»åŠ¡å¤„ç†æ—¶é—´**: ä»å¼€å§‹åˆ°å®Œæˆçš„æ€»æ—¶é—´
- **é˜Ÿåˆ—ç­‰å¾…æ—¶é—´**: ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­çš„ç­‰å¾…æ—¶é—´
- **è½¬æ¢é€Ÿåº¦**: æ–‡ä»¶å¤§å°/å¤„ç†æ—¶é—´
- **æˆåŠŸç‡**: æˆåŠŸä»»åŠ¡æ•°/æ€»ä»»åŠ¡æ•°
- **é‡è¯•ç‡**: é‡è¯•ä»»åŠ¡æ•°/æ€»ä»»åŠ¡æ•°

### æ—¥å¿—çº§åˆ«
- **INFO**: æ­£å¸¸æµç¨‹æ—¥å¿—
- **WARNING**: å¯æ¢å¤çš„å¼‚å¸¸æƒ…å†µ
- **ERROR**: é”™è¯¯å’Œå¼‚å¸¸
- **DEBUG**: è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯

## ğŸ”§ é…ç½®å‚æ•°

### ä»»åŠ¡å¤„ç†é…ç½®
```python
MAX_CONCURRENT_TASKS = 3        # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
TASK_TIMEOUT = 3600             # ä»»åŠ¡è¶…æ—¶æ—¶é—´(ç§’)
MAX_RETRY_COUNT = 3             # æœ€å¤§é‡è¯•æ¬¡æ•°
CLEANUP_COMPLETED_TASKS = True  # æ˜¯å¦æ¸…ç†å®Œæˆä»»åŠ¡çš„å·¥ä½œç©ºé—´
WORKSPACE_RETENTION_DAYS = 7    # å·¥ä½œç©ºé—´ä¿ç•™å¤©æ•°
```

### GPUå†…å­˜ç®¡ç†
```python
# ä»»åŠ¡å®Œæˆåè‡ªåŠ¨æ¸…ç†GPUå†…å­˜
torch.cuda.empty_cache()
gc.collect()
```

## ğŸ“ æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é—®é¢˜è¯Šæ–­

#### 1. ä»»åŠ¡é•¿æ—¶é—´å¤„äºpendingçŠ¶æ€
- æ£€æŸ¥å·¥ä½œçº¿ç¨‹æ˜¯å¦æ­£å¸¸è¿è¡Œ
- æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦æœ‰ç§¯å‹
- æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

#### 2. S3ä¸‹è½½å¤±è´¥
- éªŒè¯S3è¿æ¥é…ç½®
- æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®è®¤è®¿é—®æƒé™

#### 3. è½¬æ¢å¤±è´¥
- æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
- æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
- æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ

#### 4. ä¸Šä¼ å¤±è´¥
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- éªŒè¯S3å†™å…¥æƒé™
- æ£€æŸ¥ç£ç›˜ç©ºé—´

### æ—¥å¿—æŸ¥çœ‹å‘½ä»¤
```bash
# æŸ¥çœ‹ç‰¹å®šä»»åŠ¡æ—¥å¿—
docker exec document-converter cat /app/log_files/task_123.log

# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
docker logs document-converter

# å®æ—¶ç›‘æ§æ—¥å¿—
docker logs -f document-converter
```
